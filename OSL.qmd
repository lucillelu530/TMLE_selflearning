---
title: "OnlineSuperLearner"
format: html
editor: visual
---

A self-learning guide to briefly introduce key concepts and toy examples.

## Related concepts

-   Offline estimation: Traditional machine learning & forecasting paradigm; refers to "learners" or "Algorithm"

    -   New batches of data are added to the training set, and then learners are updated on the new dataset, that means we have to retrain the learner on the whole new set. SO it is not scalable when updates are frequent.

-   Online estimation: Algorithms is updated with a new batch of data without revisiting past training data

    -   Catastrophic forgetting: the new information interferes with what the model has already learned.

    -   Update the data sequentially as new data arrive

    ```{r}
    library('magrittr')
      # Set the seed
      set.seed(12345)

      # Set some functions, for readability
      expit = plogis
      logit = qlogis

      # Do logging?
      log <- FALSE

      # How many cores would we like to use?
      cores = parallel::detectCores()

      # Number of items we have in our training set
      training_set_size <- 200

      # Number of items we have in our testset
      test_set_size <- 2

      # Number of iterations we want to use (this is for the online training part)
      max_iterations <- 3

      # Size of the mini batch
      mini_batch_size <- 3

      # The calculator for estimating the risk. This is just used for testing.
      cv_risk_calculator <- CrossValidationRiskCalculator$new()
      
      
      
    ```

```{r}
 B <- 1e2 #number of interations

  # The intervention we are interested in (intervene at time 2, give intervention 1, on variable A)
  intervention  <- list(when = c(2), what = c(1), variable = 'A')

  # The time of the outcome we are interested in
  tau <- 2
```

-   `when`: When should the intervention be done? (i.e., at what time $t$)
-   `what`: What should be the intervention we are doing? (e.g., set treatment to $x \in \{0,1\}$)
-   `variable`: Which variable do we consider the intervention variable? ($A$ in the TL literature)

## Simulation

First Create a simulator

```{r}
 complicated_treatment <- FALSE

  # Our covariate definition
  llW <- list(
    stochMech=function(numberOfBlocks) {
      rnorm(numberOfBlocks, 0, 10)
    },
    param=c(0, 0.5, -0.25, 0.1),
    rgen=identity
  )

  # The treatment mechanism
  llA <- list(
    stochMech=function(ww) {
      rbinom(length(ww), 1, expit(ww))
    },
    param=c(-0.1, 0.1, 0.25),
    rgen=function(xx, delta=0.05){
      probability <- delta+(1-2*delta)*expit(xx)
      rbinom(length(xx), 1, probability)
    }
  )

  # The outcome variable
  if (complicated_treatment) {
      rgenfunction = function(AW){
        aa <- AW[, "A"]
        ww <- AW[, grep("[^A]", colnames(AW))]
        mu <- aa*(0.4-0.2*sin(ww)+0.05*ww) + (1-aa)*(0.2+0.1*cos(ww)-0.03*ww)
        rnorm(length(mu), mu, sd=0.1)
      } 
  } else {
        rgenfunction = function(AW){
        aa <- AW[, "A"]
        mu <- 19 + aa*(0.9) + (1-aa)*(0.3)
        rnorm(length(mu), mu, sd=0.1)
      }
  }
  llY <- list(rgen = rgenfunction)
```

-   `stochMech`: the mechanism we use to generate the observations
-   `param`: the number of steps $t$ the mechanism is connected to the past
-   `rgen`: the mechanism for generating the observations

```{r}
# Create the simulator
  simulator  <- Simulator.GAD$new()

  # Approximate the truth under the treatment (parallize the approximation progress)
  result.approx <- parallel::mclapply(seq(B), function(bb) {
    when <- max(intervention$when)
    data.int <- simulator$simulateWAY(
      tau,
      qw = llW,
      ga = llA,
      Qy = llY,
      intervention = intervention,
      verbose = log
    )
    data.int$Y[tau]
  }, mc.cores = cores) %>%
    unlist

  # Calculate the approximation of the true parameter of interest
  psi.approx <- mean(result.approx)
```

```{r}
 data.train <- simulator$simulateWAY(training_set_size + B + 100, qw=llW, ga=llA, Qy=llY, verbose=log)
  data.test <- simulator$simulateWAY(1000, qw=llW, ga=llA, Qy=llY, verbose=log)
```

### Initialize OnlineSuperLearner

First, just like what we did in `sl3`, select a set of algorithms we wish to include.

```{r}
#Use the fixed Rscript 
detach("package:OnlineSuperLearner", unload = TRUE)
devtools::load_all("~/Desktop/UNC_grad/Reserach/Casual/TMLE_selflearning/OnlineSuperLearner")

##Double Check
getAnywhere(fit.OnlineSuperLearner)     # shows the source / namespace
```

```{r}
 algos <- list()

algos <- append(algos, list(list(algorithm = 'ML.XGBoost',
                       algorithm_params = list(alpha = 0),
                       params = list(nbins = c(6,40), online = TRUE))))

algos <- append(algos, list(list(algorithm = 'condensier::speedglmR6',
                      #algorithm_params = list(),
                      params = list(nbins = c(3,4, 5), online = FALSE))))

#Specify relevant variables
   W <- RelevantVariable$new(formula = W ~ Y_lag_1 + A_lag_1 +  W_lag_1 + Y_lag_2, family = 'gaussian')
  A <- RelevantVariable$new(formula = A ~ W + Y_lag_1 + A_lag_1 + W_lag_1, family = 'binomial')
  Y <- RelevantVariable$new(formula = Y ~ A + W, family = 'gaussian')

  variable_of_interest <- Y
  relevantVariables <- c(W, A, Y)

```

```{r}
#| message: false
#| warning: false
 #Fit the OSL
devtools::load_all("~/Desktop/UNC_grad/Reserach/Casual/TMLE_selflearning/OnlineSuperLearner")

osl  <- OnlineSuperLearner::fit.OnlineSuperLearner(
  formulae = relevantVariables,
  data = data.train,
  algorithms = algos, 
  verbose = log,

  test_set_size = test_set_size,
  initial_data_size = training_set_size / 2,
  max_iterations = max_iterations,
  mini_batch_size = (training_set_size / 2) / max_iterations)
```

```{r calculate the effect of the intervention using OLS}
  # Should we run in parallel?
  do_parallel <- FALSE

  # Would we like to have the results of the discrete (TRUE) or continuous (FALSE) osl?
  discrete = TRUE

  interventionEffectCalculator <- InterventionEffectCalculator$new(
    bootstrap_iterations = B,
    outcome_variable = 'Y',
    parallel = do_parallel
  )

  ## Generate a block from the initial data
  osl$get_summary_measure_generator$set_trajectories(data = Data.Static$new(dataset = data.test))
  data_test_full <- osl$get_summary_measure_generator$getNext(1)$traj_1

  result <- interventionEffectCalculator$evaluate_single_intervention(
    osl = osl,
    initial_data = data_test_full,
    intervention = intervention,
    tau = tau,
    discrete = discrete
  )

  result %<>% unlist
```

```{r}
  # Calculate psi
  psi.estimation <- mean(result)

  # Plot the convergence
  y1 <- cumsum(result.approx)/seq(along=result.approx)
  y2 <- cumsum(result)/seq(along=result)

  plot(y1, ylim=range(c(y1,y2)))
  par(new=TRUE)
  plot(y2, ylim=range(c(y1,y2)), col="red", axes = FALSE, xlab = "", ylab = "")

  # Print the outcome
  outcome <- paste(
    'We have approximated psi as', psi.approx, 
    'our estimate is', psi.estimation, 
    'which is a difference of:', abs(psi.approx - psi.estimation)
  )
  print(outcome)
```
